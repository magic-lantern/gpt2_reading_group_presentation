{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of GPT 117M model\n",
    "\n",
    "First, follow setup instructions from https://github.com/openai/gpt-2/blob/master/DEVELOPERS.md\n",
    "\n",
    "The 117M model file is a 475MB download..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import model, sample, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to paths in function below, expects to run from top level dir of repo\n",
    "os.chdir('/Users/seth/onedrive/Documents/Development/gpt-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='117M'\n",
    "enc = encoder.get_encoder(model_name)\n",
    "hparams = model.default_hparams()\n",
    "with open(os.path.join('models', model_name, 'hparams.json')) as f:\n",
    "    hparams.override_from_dict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(\n",
    "    seed=None,\n",
    "    nsamples=1,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the sample_model\n",
    "    :model_name=117M : String, which model to use\n",
    "    :seed=None : Integer seed for random number generators, fix seed to\n",
    "     reproduce results\n",
    "    :nsamples=0 : Number of samples to return, if 0, continues to\n",
    "     generate samples indefinately.\n",
    "    :batch_size=1 : Number of batches (only affects speed/memory).\n",
    "    :length=None : Number of tokens in generated text, if None (default), is\n",
    "     determined by model hyperparameters\n",
    "    :temperature=1 : Float value controlling randomness in boltzmann\n",
    "     distribution. Lower temperature results in less random completions. As the\n",
    "     temperature approaches zero, the model will become deterministic and\n",
    "     repetitive. Higher temperature results in more random completions.\n",
    "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
    "     considered for each step (token), resulting in deterministic completions,\n",
    "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
    "     special setting meaning no restrictions. 40 generally is a good value.\n",
    "    \"\"\"\n",
    "    if length is None:\n",
    "        length = hparams.n_ctx\n",
    "    elif length > hparams.n_ctx:\n",
    "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
    "\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        np.random.seed(seed)\n",
    "        tf.set_random_seed(seed)\n",
    "\n",
    "        output = sample.sample_sequence(\n",
    "            hparams=hparams, length=length,\n",
    "            start_token=enc.encoder['<|endoftext|>'],\n",
    "            batch_size=batch_size,\n",
    "            temperature=temperature, top_k=top_k\n",
    "        )[:, 1:]\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(os.path.join('models', model_name))\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "        generated = 0\n",
    "        while nsamples == 0 or generated < nsamples:\n",
    "            out = sess.run(output)\n",
    "            for i in range(batch_size):\n",
    "                generated += batch_size\n",
    "                text = enc.decode(out[i])\n",
    "                print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
    "                print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_model(\n",
    "    seed=None,\n",
    "    nsamples=1,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=0,\n",
    "    prompt=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Interactively run the model\n",
    "    :model_name=117M : String, which model to use\n",
    "    :seed=None : Integer seed for random number generators, fix seed to reproduce\n",
    "     results\n",
    "    :nsamples=1 : Number of samples to return total\n",
    "    :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples.\n",
    "    :length=None : Number of tokens in generated text, if None (default), is\n",
    "     determined by model hyperparameters\n",
    "    :temperature=1 : Float value controlling randomness in boltzmann\n",
    "     distribution. Lower temperature results in less random completions. As the\n",
    "     temperature approaches zero, the model will become deterministic and\n",
    "     repetitive. Higher temperature results in more random completions.\n",
    "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
    "     considered for each step (token), resulting in deterministic completions,\n",
    "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
    "     special setting meaning no restrictions. 40 generally is a good value.\n",
    "    \"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "    assert nsamples % batch_size == 0\n",
    "\n",
    "    if length is None:\n",
    "        length = hparams.n_ctx // 2\n",
    "    elif length > hparams.n_ctx:\n",
    "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
    "\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
    "        np.random.seed(seed)\n",
    "        tf.set_random_seed(seed)\n",
    "        output = sample.sample_sequence(\n",
    "            hparams=hparams, length=length,\n",
    "            context=context,\n",
    "            batch_size=batch_size,\n",
    "            temperature=temperature, top_k=top_k\n",
    "        )\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(os.path.join('models', model_name))\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "        context_tokens = enc.encode(prompt)\n",
    "        generated = 0\n",
    "        for _ in range(nsamples // batch_size):\n",
    "            out = sess.run(output, feed_dict={\n",
    "                context: [context_tokens for _ in range(batch_size)]\n",
    "            })[:, len(context_tokens):]\n",
    "            for i in range(batch_size):\n",
    "                generated += 1\n",
    "                text = enc.decode(out[i])\n",
    "                print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
    "                print(text)\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/seth/anaconda3/envs/gpt2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/seth/OneDrive - The University of Colorado Denver/Documents/Development/gpt-2/src/sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/seth/OneDrive - The University of Colorado Denver/Documents/Development/gpt-2/src/sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING:tensorflow:From /Users/seth/anaconda3/envs/gpt2/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n",
      "======================================== SAMPLE 1 ========================================\n",
      ": Checking Technologies to Tear Down Big Banks Investments Ernest Chris Pearl , S. Gelles , Y. Husain , Philip : Cheers. Until I realized they were part of an oligarchy yet they turned down my requests. RIA Novosti : Hey, Eroded, nice profile. Such companies don't want to pay you a penny: Cheers. Until I realised they were part of an oligarchy yet they turned down my requests. Uniprole Press : Such companies don't want to pay you a penny: Guess you said yes? They said no. OrderMark : No much, handle it. Ignoring any outrage about unreasonable paperwork, they said don't. Switchgrass Entertainment United CtrlId #LoggingStraight : That tech is unethical, they accepted my request. Evangelus Returned $1.8B How about this: Easy BricksScholar : I respect this tech sooo i would'nt take the risk. Not that you need an IT degree. Just that you may need it badly ones have free internet, economics, etc... : Engineering Gravitasoftofthoma : This tech sooooooo uses a benchmark GPA changelog engine to produce this data, except: Mercedes : None - true if u dont understand buts forwarding their growth certificate to me huh... Graduate in finance, government, and training under The Asian Academy At the end of the day each company in America has a new citizens card with eligibility standards which various governments a startup seeks to work with. May be that this is one of the reasons there isn't any option for those to game the system it has proprietary areas. Cloverleaf Systems & Data Sipedron : Texas A&M University are pioneering these kinds of smartphone giants by using public domain HTML million librarians to run their specially trained volunteers. Many of the tech community amateurs are showing results like Java class management and Webcams so maybe some younger guys won't mind to blow me out even if the school came unannounced. Klara Universal Simple Connections : New WiFi suppliers Aprox i1 10:20agfl an Jeff Davis Memorial : Most of the people I know on the Freelancer's immediate team except for a few little (newslan id stickied) Instagram-SIST Ambassadors CarollaCalories : Put money into your clone you only have it ASS BECOME ASSED as you battle this insanity (routing smart rigs and averaging out with it). Guild Of Linuxmodgl.com : their STOL Ecommerce tech , Don't give us shit technologies that suck for SP Pace F-Consume : Your cool hack today Appex and With Flake Street : Paternality : ClockworkAmazing : Only resale Everything for a gun, drug or whatever Effector of the Future : Butchexplys@gmail.com : Opponents in attitude to you Simply Atheist Even though I have some decent standards and regulations, sometimes I need a handcuff to an automated wire fence staying open for 24 hours never to return. Cruel Albatross : If you dont believe me, think about your flight package. Have this in mind, email me: mmeanten@cptgroup.net -Photos: miambraliii@hotmail.com\n",
      "\n",
      "Code<|endoftext|>HOFHP (Connecting Fishes)\n",
      "\n",
      "I'm now his apprentice! Help him get to that perfect craft! Bonus: 5% Credit to online merchants. Me and you have 1 fishboat!<|endoftext|>One of the more interesting illustrations released in disposition or chronology is from Michael Clara, which shows a young bride over the course of (or during) her journey to a global exotic destination: Peru is a tourist destination, whereas Morocco a largely historic country interviewed largely aficionados of central and central American art. I hope I borrowed this as a huge cautionary tale, seeing things as they are for as many different perspective Asianos at the present moment as I could get my hands on. (Or, more exactly, to learn more about what Michael Clara has to explain.)<|endoftext|>Israeli Paramilitary Force UPDATES One of the most frightening aspects of yesterday's September 11 attacks by Islamic State of Iraq and Syria (ISIS) militants has been the clash between rockets and IDF soldiers stationed on both sides of the border and the fire of more than 20 rounds of Israeli white phosphorus. Hundreds of a hundred IDF soldiers were killed in this confrontation based on the lack of fire.\n",
      "\n",
      "Onstanders of Operation Protective Edge at Plaqueminesque, where IDF forces were reduced to using orange juice and rubber bullets in this clash, reputedly used water Holes did not fire, and that resulted in virtually no Israeli casualties. Leicester Berlin, the city in which the two terrorist attack schemes occured, has suffered 50 rockets dropped by mortars on its front entrance. Hundreds more likely to victimise Christians were killed, while Jewish Americans (and a number of Jewish women) were killed. The deaths to come are not only a testament to the cruelty of what happened yesterday,\n",
      "CPU times: user 2min 14s, sys: 2min 39s, total: 4min 53s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_model(seed=42)\n",
    "# takes about 15 seconds when running with 1 x NVIDIA Tesla T4\n",
    "# on macbook pro 1:30\n",
    "# ~ 6 times slower with CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n",
      "======================================== SAMPLE 1 ========================================\n",
      "I've been using the X1 with my 2 year old for a decade now. It's been really fun to use. I loved the way it works and was really impressed with how easy it was to use. The cable comes with an extra cord so you can plug in whatever you want. The X1 is very sturdy and easy to use. It's not big, but it's not big or heavy. The cable is sturdy. The cable comes with an extra cord so you can plug in whatever you want. The X1 is very sturdy and easy to use. It's not big, but it's not big or heavy. The cable is sturdy. The cable comes with an extra cord so you can plug in whatever you want.\n",
      "\n",
      "Rated 5 out of 5 by Anonymous from Nice to use This cable is great for any situation. It's easy to use and it's also quick to use. I would recommend this cable to anyone who wants a good, reliable cable that would work with most other cables. I would recommend this cable to anyone who wants a good, reliable cable that would work with most other cables.\n",
      "\n",
      "Rated 4 out of 5 by Anonymous from Great cable Great cable\n",
      "\n",
      "Rated 5 out of 5 by Anonymous from I'm 6 years old and enjoy using the X1. I'm 6 years old and enjoy using the X1.\n",
      "\n",
      "Rated 4 out of 5 by Anonymous from Great cable and fast cable I purchased this cable from Home Depot. It worked great, and I can now use it on my 2 year old. The cable is a very strong, solid cable. I did not have any problems using it, but I did find there was a little bit of a looooong way to use it. I could not get it to come on when I was using it. I also needed to use it with a smaller cord. The cable fit with the larger one. I also needed to use it with an extra cable. The cable didn't come on very frequently. I would recommend this cable and this little tool.\n",
      "\n",
      "Rated 4 out of 5 by Anonymous from Great cable This cable fits my 2 year old. We have her in a big car. The cable has been good for a while now. We had a 2 year old using it and she loves it. We have a 3 year old that loves it too.\n",
      "\n",
      "Rated 4 out of 5 by Anonymous from Quick and easy to use Great cable, great price, no issues with damage or other issues.\n",
      "\n",
      "Rated 5 out of 5 by Anonymous from Very good cable I am using this as a replacement for a old 3 year old. We are both 6 months old, and both of us have 2 older kids that need a new cable. The cable comes out great, and my little girl has a very clean, clean cable. It is a good quality cable that will keep her going. I have used it for the last 2 years and she loves it. She is a very happy little girl.\n",
      "\n",
      "Rated 5 out of 5 by Anonymous from Great cable This cable is great for small-size, 2 year old. We have a 2 year old. She loves it, and when I put it to bed, she loves it. She's happy.<|endoftext|>The following article, \"A few weeks ago I was getting up in the morning and I was running around in a little dark alleyway. I was talking to a woman and I had to stop at a gas station and I was trying to figure out what to do. I was talking to someone who was smoking a cigar and I said 'You're not going to be in any trouble. You're going to be fine.' 'I know you're a Mexican and you're gonna pay for it, but do you know how to get out of there?' 'I don't know, but I know you're a good guy, man.' I said, 'And you're going to pay for it? I'm gonna pay for it.'\n",
      "\n",
      "\"I said, 'You're not going to pay for it? You're going to pay for it?' 'I know you're a good guy, man.' 'I said, 'And you're going to pay for it?' 'I know you're a good guy, man.' 'I said, 'And you're going to pay for it?' 'I know you're a good guy, man.'\n",
      "\n",
      "\"She said, 'You don't know how to pay for it, man. You don't know how to pay for it.' I said, 'You don't know how to pay for it, man. You don't know how to pay for it.' 'I know you're a good guy, man.' 'I said, 'And you're going to pay for it?' 'I know you're a good guy, man.' 'I said, 'And you're going to pay for it?' 'I know you're a good guy, man.' 'I said, 'And you're going to pay for it?' 'I\n",
      "CPU times: user 2min 10s, sys: 2min 37s, total: 4min 47s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_model(seed=42, top_k=40, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n",
      "======================================== SAMPLE 1 ========================================\n",
      "\n",
      "\n",
      "\n",
      "As I said earlier, I think it's fair to say that the error with the\n",
      "\n",
      "toughness statement appeared in the new content, as is the fact that the original\n",
      "\n",
      "text was not only too late, but was almost certainly wrong. \n",
      "\n",
      "\n",
      "I'll give you the best possible statement of that, as you can probably tell from the\n",
      "\n",
      "comment comment.  It is not clear until after the correction that the\n",
      "\n",
      "errors were completely intentional.  I don't know if it was intentional, or if the\n",
      "\n",
      "criteria were so wrong as to warrant the correction. \n",
      "\n",
      "\n",
      "The last thing I would say is that I think this is a good\n",
      "\n",
      "revision by Jonathan S. Ehrlich, and I would like to thank him for the\n",
      "\n",
      "review of the new content.  I would also like to thank you for your time.\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CPU times: user 20.4 s, sys: 13.2 s, total: 33.5 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "interact_model(seed=42, top_k=100, length=183, prompt=\"\"\"Hi Seth,\n",
    "\n",
    "I worked off of Tell's corrected letter, much of which I agree with.  The one thing\n",
    "I can tell you is that if you put the edited text in both the response letter and\n",
    "in the revision, then that will help the referees.  This is not for typographical\n",
    "changes but for the substantive changes.  I have indicated in the response letter\n",
    "where it would be good for you to add in what text you wrote to address/clarify the\n",
    "comments.\n",
    "\n",
    "\n",
    "This is a really good paper, and I appreciate your involving us with it.\n",
    "\n",
    "Best,\n",
    "Debashis\"\"\", temperature=0.75)\n",
    "# performance highly dependent on parameters\n",
    "# on 1 x NVIDIA Tesla T4 10 seconds\n",
    "# on macbook pro 39 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n",
      "======================================== SAMPLE 1 ========================================\n",
      "\n",
      "\n",
      "...We should never forget that the National Abortion Federation’s position on abortion was that it was a health care measure that should be\n",
      "\n",
      "protected as a right’ and that the right to life was a fundamental right’\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CPU times: user 8.39 s, sys: 1.96 s, total: 10.4 s\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "interact_model(seed=42, top_k=100, length=51, prompt=\"\"\"Senate Democrats just voted against legislation\n",
    "to prevent the killing of newborn infant children. The Democrat position on abortion is now so extreme\n",
    "that they don’t mind executing babies AFTER birth....\n",
    "\n",
    "....This will be remembered as one of the most shocking votes in the history of Congress. If there is one\n",
    "thing we should all agree on, it’s protecting the lives of innocent babies.\"\"\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
